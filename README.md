# ğŸ§  Foundation Models for Vision, Language & Action

<p align="center">
  <img src="main.png" alt="Foundation Models Header" width="600"/>
  <br>
  <sub><em>Made by AI with ğŸ’» compute</em></sub>
</p>

---

## 1ï¸âƒ£ Vision Models

### âœ”ï¸ Papers Done
- **CLIP** â€“ [Contrastive Languageâ€“Image Pretraining (2021)](https://arxiv.org/abs/2103.00020)
- **ViT** â€“ [An Image is Worth 16x16 Words (2020)](https://arxiv.org/abs/2010.11929)

---

## 2ï¸âƒ£ Language Models

### âœ”ï¸ Papers Done
- **Mistral MoE** â€“ [Mixtral of Experts (2023)](https://arxiv.org/abs/2401.04088)
- **GPT-2** â€“ [Language Models are Unsupervised Multitask Learners (2019)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

---

## 3ï¸âƒ£ Action Models ğŸ¤–

### â³ To Be Updated
- *(Work in progress)*
