{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wandb\n",
    "%pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import math  \n",
    "from dataclasses import dataclass \n",
    "from tokenizers import Tokenizer \n",
    "from pathlib import Path \n",
    "from torch.utils.data import Dataset , DataLoader \n",
    "import wandb \n",
    "from transformers import AutoTokenizer , AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class Config:\n",
    "    dpo_model_name : str = \"mistralai/Mistral-7B-Instruct\"\n",
    "    model_name : str = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "    dataset_name: str = \"trl-lib/ultrafeedback_binarized\"\n",
    "    batch_size : int = 2 \n",
    "    beta : float = 0.1 \n",
    "    learning_rate : float = 1e-4 \n",
    "    HF_TOKEN : str = \"PASS\"\n",
    "    device : str = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"dpo-finetune\" , \n",
    "           config = Config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPO:\n",
    "    def __init__(self , config: Config):\n",
    "        self.config = Config()\n",
    "        self.ref_model = AutoModelForCausalLM.from_pretrained(self.config.dpo_model_name , token = self.config.HF_TOKEN)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.config.model_name , token = self.config.HF_TOKEN) \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.config.model_name , token = self.config.HF_TOKEN) \n",
    "        self.ref_model.eval()\n",
    "    \n",
    "    def DPOLoss(self , datapoint):\n",
    "        self.win_prompt  = datapoint['chosen']\n",
    "        self.lose_prompt = datapoint[\"rejected\"]\n",
    "        \"\"\"Compute the DPO loss for a single datapoint\"\"\"\n",
    "        with torch.no_grad():\n",
    "            self.win_ref_model = torch.nn.functional.log_softmax(self.ref_model(self.win_prompt).logits , dim = -1)\n",
    "            self.lose_ref_model = torch.nn.functional.log_softmax(self.ref_model(self.lose_prompt).logits , dim = -1)\n",
    "            self.win_ref_model = torch.gather(self.win_ref_model , dim = -1 , index = self.win_prompt['input_ids'].unsqueeze(-1)).squeeze(-1)\n",
    "            self.lose_ref_model = torch.gather(self.lose_ref_model , dim = -1 , index =  self.lose_prompt['input_ids'].unsqueeze(-1)).squeeze(-1)\n",
    "            self.win_ref_model = self.win_ref_model * self.win_prompt['attention_mask']\n",
    "            self.lose_ref_model = self.lose_ref_model * self.lose_prompt['attention_mask']\n",
    "            self.win_ref_model = self.win_ref_model.sum(dim = -1)\n",
    "            self.lose_ref_model = self.lose_ref_model.sum(dim = -1)\n",
    "            \n",
    "            self.win_model = torch.nn.functional.log_softmax(self.model(self.win_prompt).logits , dim = -1)\n",
    "            self.lose_model = torch.nn.functional.log_softmax(self.model(self.lose_prompt).logits , dim = -1)\n",
    "            self.win_model = torch.gather(self.win_model , dim = -1  , index = self.win_prompt['input_ids'].unsqueeze(-1)).squeeze(-1)\n",
    "            self.lose_model = torch.gather(self.lose_model , dim = -1  , index = self.lose_prompt['input_ids'].unsqueeze(-1)).squeeze(-1)\n",
    "            self.win_model = self.win_model * self.win_prompt['attention_mask']\n",
    "            self.lose_model = self.lose_model * self.lose_prompt['attention_mask']\n",
    "            self.win_model = self.win_model.sum(dim = -1)\n",
    "            self.lose_model = self.lose_model.sum(dim = -1)\n",
    "            \n",
    "            self.diff1 = self.win_model - self.win_ref_model\n",
    "            self.diff2 = self.lose_model - self.lose_ref_model \n",
    "            self.loss = - nn.functional.logsigmoid(self.config.beta * (self.diff1 - self.diff2)).mean()\n",
    "            \n",
    "            return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(Config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device - Do not run this cell untill you get Device SSH key \n",
    "torch.cuda.set_device(Config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce96629b00c94d8298ecd4d282e4159d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/643 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24568ba3aac04f3e87dfcbc884c0d5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/131M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d04e38d96b4fcbbd420765054eddf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/2.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28027a1892ce439d9af93ca55bc80ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/62135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219b2695cf23463b930790d8c28f6e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "train_dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\")\n",
    "val_dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"test\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chosen': [{'content': 'Use the pygame library to write a version of the classic game Snake, with a unique twist', 'role': 'user'}, {'content': \"Sure, I'd be happy to help you write a version of the classic game Snake using the pygame library! Here's a basic outline of how we can approach this:\\n\\n1. First, we'll need to set up the game display and create a game object that we can use to handle the game's state.\\n2. Next, we'll create the game's grid, which will be used to represent the game board. We'll need to define the size of the grid and the spaces within it.\\n3. After that, we'll create the snake object, which will be used to represent the player's movement. We'll need to define the size of the snake and the speed at which it moves.\\n4. We'll also need to create a food object, which will be used to represent the food that the player must collect to score points. We'll need to define the location of the food and the speed at which it moves.\\n5. Once we have these objects set up, we can start handling the game's logic. We'll need to define the rules for the player's movements, such as how the player can move the snake and how the snake will grow as the player collects more food.\\n6. We'll also need to add collisions detection to the game, so that the snake and the food can collide with each other.\\n7. Finally, we'll need to add a user interface to the game, such as a menu and a scoreboard.\\n\\nNow, as for the unique twist, we could add a few features to make the game more interesting. For example, we could add power-ups that give the player special abilities, such as the ability to grow the snake faster or to change its direction. We could also add obstacles, such as walls or pits, that the player must avoid.\\n\\nHere's some sample code to get us started:\\n```\\nimport pygame\\n\\n# Initialize pygame\\npygame.init()\\n\\n# Set up the game display\\nwidth = 800\\nheight = 600\\nscreen = pygame.display.set_mode((width, height))\\n\\n# Define the colors\\nWHITE = (255, 255, 255)\\nBLACK = (0, 0, 0)\\nGREEN = (0, 255, 0)\\n\\n# Define the game objects\\nsnake = pygame.Rect(50, 50, 10, 10)\\nfood = pygame.Rect(100, 100, 10, 10)\\n\\n# Define the game logic\\ndef update_snake():\\n    # Get the mouse position\\n    mouse_pos = pygame.mouse.get_pos()\\n\\n    # Move the snake based on the mouse position\\n    if mouse_pos[0] > snake.x:\\n        snake.x += 10\\n    elif mouse_pos[0] < snake.x:\\n        snake.x -= 10\\n    elif mouse_pos[1] > snake.y:\\n        snake.y += 10\\n    elif mouse_pos[1] < snake.y:\\n        snake.y -= 10\\n\\n    # Update the snake's size\\n    if snake.x == food.x and snake.y == food.y:\\n        snake.width += 10\\n        snake.height += 10\\n\\n# Define the game loop\\ndef game_loop():\\n    # Clear the screen\\n    screen.fill(BLACK)\\n\\n    # Update the game objects\\n    update_snake()\\n\\n    # Draw the game objects\\n    screen.fill(WHITE)\\n    screen.draw.rect(snake, GREEN)\\n    screen.draw.rect(food, BLACK)\\n\\n    # Update the display\\n    pygame.display.flip()\\n\\n# Start the game loop\\ngame_loop()\\n\\n# Run the game\\nwhile True:\\n    for event in pygame.event.get():\\n        if event.type == pygame.QUIT:\\n            pygame.quit()\\n            break\\n\\n    pygame.time.Clock().tick(60)\\n```\\nThis code sets up a basic game display, defines the snake and food objects, and updates the game state based on the player's movements. We've also added a simple user interface and some basic collision detection.\\n\\nAs for the unique twist, we could add a few features to make the game\", 'role': 'assistant'}], 'rejected': [{'content': 'Use the pygame library to write a version of the classic game Snake, with a unique twist', 'role': 'user'}, {'content': 'Sure, here\\'s an example of how to write a version of Snake game with a unique twist using the Pygame library:\\n```python\\nimport pygame\\n\\nclass SnakeGame:\\n    def __init__(self, game_width, game_height):\\n        pygame.init()\\n        screen = pygame.display.set_mode((game_width, game_height))\\n        pygame.display.set_caption(\"Snake Game\")\\n        self.speed = 5  # Speed of the snake\\n        self.food_speed = 1  # Speed of the food\\n        self.direction = 0  # Initial direction of the snake\\n        self.snakelen = 0  # Length of the snake\\n        self.food = pygame.image.load(\"snake_food.png\")\\n        self.head = pygame.image.load(\"snake_head.png\")\\n        self.tail = pygame.image.load(\"snake_tail.png\")\\n        self.game Quint()\\n    def Quint(self):\\n        for i in range(50):\\n            pygame.draw.line(screen, (180, 100, 220), (0, 0, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 0, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 50, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 50, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 80, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (50, 80, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 50, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 50, 300), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 80, 200), 2)\\n            pygame.draw.line(screen, (180, 100, 220), (0, 80, 300), 2)\\n            pygame.display.flip()\\n        self.game.run()\\n    def run(self):\\n        while True:\\n            for event in pygame.event. pygame.KEYDOWN:\\n                if event.key == pygame.K_LEFT:\\n                    self.direction = -1\\n                if event.key == pygame.K_RIGHT:\\n                    self.direction = 1\\n            self.snakelen += 1\\n            if self.snakelen == 0:\\n                self.snakelen = 10\\n            if self.snakelen > 20:\\n                self.snakelen = 20\\n            self.gameQuint()\\n            self.foodCrossing()\\n            self.headRun()\\n            pygame.display.update()\\ngame = SnakeGame(800, 600)\\ngame.run()\\n```\\nIn this game, the snake moves with a constant speed, but the direction of the snake can be controlled by the user using the left and right arrow keys. The snake grows in length every 10 segments, and when it reaches a certain length, it resets to 10 segments. The food moves fast and randomly crosses the screen, and the snake can eat it by colliding with it. The snake\\'s head and tail move independently of each other. The game ends when the snake dies or reaches the end of the screen.', 'role': 'assistant'}], 'score_chosen': 6.0, 'score_rejected': 4.0}\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and dataset final CELLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpo_collate_fn_merged_prompt(batch):\n",
    "\n",
    "    merged_chosen_prompts = []\n",
    "    merged_rejected_prompts = []\n",
    "\n",
    "    for sample in batch:\n",
    "\n",
    "        # Extract and merge chosen response\n",
    "        prompt = sample['prompt']\n",
    "        chosen_data = sample['chosen']\n",
    "        chosen_data = \"Instruction: \" + prompt + \"\\n\" + \"Output: \" + chosen_data[1]['content'] + \"\\n\"\n",
    "        # Extract and merge rejected response\n",
    "        rejected_data = sample['rejected']\n",
    "        rejected_data =  \"Instruction: \" + prompt + \"\\n\" + \"Output: \" + rejected_data[1]['content'] + \"\\n\"\n",
    "        # print(chosen_data)\n",
    "        # print(rejected_data)\n",
    "        merged_chosen_prompts.append(chosen_data)\n",
    "        merged_rejected_prompts.append(rejected_data)\n",
    "    tokenized_win_prompt = tokenizer(merged_chosen_prompts, max_length = 1024, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    tokenized_lose_prompt = tokenizer(merged_rejected_prompts, max_length = 1024, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "    return {\n",
    "        'chosen': tokenized_win_prompt,\n",
    "        'rejected': tokenized_lose_prompt \n",
    "    }\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, collate_fn=dpo_collate_fn_merged_prompt)\n",
    "val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=True, collate_fn=dpo_collate_fn_merged_prompt)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters() , lr = Config.learning_rate)\n",
    "total_steps = len(train_dataset) // Config.batch_size\n",
    "eval_iterations = 100 \n",
    "dpo_loss = DPO(Config)\n",
    "train_iterator = iter(train_loader)\n",
    "val_iterator = iter(val_loader)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def estimate_loss():\n",
    "    loader = None \n",
    "    out = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for split in ['train' , 'val']:\n",
    "            if (split == 'train'):\n",
    "                loader = train_loader\n",
    "            elif(split == 'val'):\n",
    "                loader = val_loader\n",
    "            losses = torch.zeros(eval_iterations)\n",
    "            for k in range(eval_iterations):\n",
    "                datapoint = next(loader)\n",
    "                loss = dpo_loss.DPOLoss(datapoint)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "        model.train()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model \n",
    "from tqdm import tqdm \n",
    "train_iterator = iter(train_loader)\n",
    "\n",
    "for step in tqdm(range(total_steps)):\n",
    "    losses = estimate_loss()\n",
    "    print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    wandb.log({\n",
    "            \"step\": step,\n",
    "            \"training_loss\": losses['train'],\n",
    "            \"val_loss\": losses['val']\n",
    "        })\n",
    "    text = next(train_iterator)\n",
    "    loss = dpo_loss.DPOLoss(text)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        wandb.log({\n",
    "            \"step\": step,\n",
    "            \"training_loss\": losses['train'],\n",
    "            \"val_loss\": losses['val']})\n",
    "        \n",
    "print(\"Training Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
